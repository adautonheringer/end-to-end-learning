{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Rescaling, Cropping2D, concatenate\n",
    "from keras.models import Sequential, load_model\n",
    "from keras import Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import zipfile\n",
    "import h5py\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Multicamera_15'\n",
    "version = 'version_1'\n",
    "dataset_path = f'/tf/datasets/{model_name.lower()}.h5'\n",
    "base_dir = '/tf/Models'\n",
    "work_dir = os.path.join(base_dir, model_name, version)\n",
    "\n",
    "data = h5py.File(dataset_path,  'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(work_dir, 'weights_improvement_{epoch:02d}_{val_loss:.4f}.hdf5')\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='min')\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=30, verbose=1, mode='auto')\n",
    "callbacks = [checkpoint, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, file, list_IDs, batch_size=32):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.file = file\n",
    "        self.list_IDs = list_IDs\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'   \n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "\n",
    "        indexes = self.list_IDs[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        IMAGES = self.file['images'][indexes]\n",
    "        INPUT_2 = self.file['input_2'][indexes]\n",
    "        LABELS = self.file['labels'][indexes]\n",
    "\n",
    "        return [IMAGES, INPUT_2], LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    img_inputs = keras.Input(shape=(180, 300, 3))\n",
    "    cropping = Cropping2D(cropping=((70, 0), (0, 0)))\n",
    "    rescaling = Rescaling(scale=1. / 255, offset=-0.5)\n",
    "    x = cropping(img_inputs)\n",
    "    x = Rescaling(scale=1. / 255, offset=-0.5)(x)\n",
    "    x = Conv2D(24, (5, 5), strides=(2, 2), activation=\"relu\")(x)\n",
    "    x = Conv2D(36, (5, 5), strides=(2, 2), activation=\"relu\")(x)\n",
    "    x = Conv2D(48, (5, 5), strides=(2, 2), activation=\"relu\")(x)\n",
    "    x = Conv2D(64, (3, 3), strides=(2, 2), activation=\"relu\")(x)\n",
    "    x = Conv2D(64, (3, 3), strides=(1, 1), activation=\"relu\")(x)\n",
    "    x = Conv2D(64, (3, 3), strides=(1, 1), activation=\"relu\")(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dense(100)(x)\n",
    "    x = Model(inputs=img_inputs, outputs=x)\n",
    "    hlc_inputs = keras.Input(shape=(6))\n",
    "    combined = concatenate([x.output, hlc_inputs])\n",
    "    z = Dense(100, activation=\"relu\")(combined)\n",
    "    z = Dense(50, activation=\"relu\")(z)\n",
    "    z = Dense(10, activation=\"relu\")(z)\n",
    "    output = Dense(3)(z)\n",
    "    model = Model(inputs=[x.input, hlc_inputs], outputs=output)\n",
    "    # keras.utils.plot_model(model, show_shapes=True, dpi=50)\n",
    "    model.compile(optimizer='Adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = data['images'].shape[0]\n",
    "training = math.floor(n*0.80)\n",
    "list_IDs_train = np.arange(training)\n",
    "list_IDs_val = np.arange(training, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13497/13500 [============================>.] - ETA: 0s - loss: 0.0219"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    DataGenerator(file=data, list_IDs=list_IDs_train),\n",
    "    validation_data=DataGenerator(file=data, list_IDs=list_IDs_val),\n",
    "    epochs=100,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(work_dir, f'{model_name.lower()}_history.npy'), history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tf/Models/Multicamera_7/version_1/multicamera_7_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tf/Models/Multicamera_7/version_1/multicamera_7_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(os.path.join(work_dir, f'{model_name.lower()}_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
